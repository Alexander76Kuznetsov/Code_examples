{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a564d5f",
      "metadata": {
        "id": "3a564d5f"
      },
      "source": [
        "#  Преобразование текстов в последовательность индексов токенов. Torchtext.\n",
        "\n",
        "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
        "\n",
        "Материалы:\n",
        "* Deep Learning with PyTorch (2020) Авторы: Eli Stevens, Luca Antiga, Thomas Viehmann\n",
        "* https://pytorch.org/text/stable/\n",
        "* https://pytorch.org/text/stable/vocab.html\n",
        "* https://pytorch.org/text/stable/transforms.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9ecd663",
      "metadata": {
        "id": "c9ecd663"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a10d94",
      "metadata": {
        "id": "a3a10d94"
      },
      "source": [
        "1\\. Рассмотрите основные шаги по преобразованию текста в последовательность индексов токенов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "72ce64eb",
      "metadata": {
        "id": "72ce64eb"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"Студенты усердно занимаются стремясь получить знания и достичь успеха\",\n",
        "    \"Студенты активно участвуют в общественной жизни университета\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYz7oecrlXGM",
        "outputId": "44eb9c48-be94-44c4-8304-cd466a068116"
      },
      "id": "PYz7oecrlXGM",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_t = [\n",
        "    word_tokenize(text.lower())\n",
        "    for text in corpus\n",
        "]\n",
        "corpus_t"
      ],
      "metadata": {
        "id": "MDF0teVFltjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045358db-fa4a-4076-a91b-5e2e02a2bb7e"
      },
      "id": "MDF0teVFltjQ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['студенты',\n",
              "  'усердно',\n",
              "  'занимаются',\n",
              "  'стремясь',\n",
              "  'получить',\n",
              "  'знания',\n",
              "  'и',\n",
              "  'достичь',\n",
              "  'успеха'],\n",
              " ['студенты',\n",
              "  'активно',\n",
              "  'участвуют',\n",
              "  'в',\n",
              "  'общественной',\n",
              "  'жизни',\n",
              "  'университета']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8lUe_iToyYD",
        "outputId": "8877d1e5-5e9f-4b20-d924-3f3af24339f1"
      },
      "id": "O8lUe_iToyYD",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['студенты',\n",
              "  'усердно',\n",
              "  'занимаются',\n",
              "  'стремясь',\n",
              "  'получить',\n",
              "  'знания',\n",
              "  'и',\n",
              "  'достичь',\n",
              "  'успеха'],\n",
              " ['студенты',\n",
              "  'активно',\n",
              "  'участвуют',\n",
              "  'в',\n",
              "  'общественной',\n",
              "  'жизни',\n",
              "  'университета']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = set()\n",
        "words.update(corpus_t[0])\n",
        "words.update(corpus_t[1])\n",
        "words = list(words)"
      ],
      "metadata": {
        "id": "bAWVh7lul1YE"
      },
      "id": "bAWVh7lul1YE",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = words"
      ],
      "metadata": {
        "id": "-d7rOQYWmFbP"
      },
      "id": "-d7rOQYWmFbP",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnsr0WEBsYFP",
        "outputId": "f33c6755-91b3-4745-b9f0-0b4bd22328f4"
      },
      "id": "wnsr0WEBsYFP",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['стремясь',\n",
              " 'жизни',\n",
              " 'университета',\n",
              " 'получить',\n",
              " 'усердно',\n",
              " 'в',\n",
              " 'и',\n",
              " 'активно',\n",
              " 'общественной',\n",
              " 'достичь',\n",
              " 'успеха',\n",
              " 'занимаются',\n",
              " 'участвуют',\n",
              " 'студенты',\n",
              " 'знания']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {v: idx for idx, v in enumerate(itos)}"
      ],
      "metadata": {
        "id": "4Si_vrr3mRQE"
      },
      "id": "4Si_vrr3mRQE",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos[0], stoi[\"стремясь\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m7TCgTMmW2s",
        "outputId": "5351f1c0-393a-4416-9852-07cabb5245ae"
      },
      "id": "1m7TCgTMmW2s",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('стремясь', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlpwzr7BvcZ3",
        "outputId": "0a91e8cd-893f-4e63-a3af-43a836e8b321"
      },
      "id": "xlpwzr7BvcZ3",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'стремясь': 0,\n",
              " 'жизни': 1,\n",
              " 'университета': 2,\n",
              " 'получить': 3,\n",
              " 'усердно': 4,\n",
              " 'в': 5,\n",
              " 'и': 6,\n",
              " 'активно': 7,\n",
              " 'общественной': 8,\n",
              " 'достичь': 9,\n",
              " 'успеха': 10,\n",
              " 'занимаются': 11,\n",
              " 'участвуют': 12,\n",
              " 'студенты': 13,\n",
              " 'знания': 14}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_i = [\n",
        "    [stoi[t] for t in tokens]\n",
        "    for tokens in corpus_t\n",
        "]"
      ],
      "metadata": {
        "id": "p-VvhjtzmYi9"
      },
      "id": "p-VvhjtzmYi9",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxwOGdTEmtQF",
        "outputId": "afda5389-04c6-466d-d35b-f081204a2949"
      },
      "id": "gxwOGdTEmtQF",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[13, 4, 11, 0, 3, 14, 6, 9, 10], [13, 7, 12, 5, 8, 1, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as th"
      ],
      "metadata": {
        "id": "3voYVmf3mtMO"
      },
      "id": "3voYVmf3mtMO",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_i[1].extend((-1, -1)) # padding"
      ],
      "metadata": {
        "id": "C1uVC5f2nEa8"
      },
      "id": "C1uVC5f2nEa8",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "th.tensor(corpus_i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyxeRxiIm3FU",
        "outputId": "fbfbf8d1-464b-4868-8e56-089b45e5a281"
      },
      "id": "GyxeRxiIm3FU",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[13,  4, 11,  0,  3, 14,  6,  9, 10],\n",
              "        [13,  7, 12,  5,  8,  1,  2, -1, -1]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8785be82",
      "metadata": {
        "id": "8785be82"
      },
      "source": [
        "2\\. Рассмотрите процесс создания `Vocab` из `torchtext`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext"
      ],
      "metadata": {
        "id": "uj2J7ipznrio"
      },
      "id": "uj2J7ipznrio",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchtext.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5ijHb01Gn37M",
        "outputId": "14251aa2-5c56-43ca-bc9d-5e105e733a23"
      },
      "id": "5ijHb01Gn37M",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.15.2+cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "XiKZE439osvj"
      },
      "id": "XiKZE439osvj",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_daSKI6Zs0T8",
        "outputId": "3a623cd0-b890-4b5d-c12e-ace5a04f3ff8"
      },
      "id": "_daSKI6Zs0T8",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['студенты',\n",
              "  'усердно',\n",
              "  'занимаются',\n",
              "  'стремясь',\n",
              "  'получить',\n",
              "  'знания',\n",
              "  'и',\n",
              "  'достичь',\n",
              "  'успеха'],\n",
              " ['студенты',\n",
              "  'активно',\n",
              "  'участвуют',\n",
              "  'в',\n",
              "  'общественной',\n",
              "  'жизни',\n",
              "  'университета']]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(\n",
        "    corpus_t\n",
        ")"
      ],
      "metadata": {
        "id": "FGHLbT6voupO"
      },
      "id": "FGHLbT6voupO",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqJyRpVzs-pQ",
        "outputId": "e9047981-ff01-4042-d1e4-cd8626a22ad7"
      },
      "id": "NqJyRpVzs-pQ",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Vocab()"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.lookup_indices([\"занимаются\", \"стремясь\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8m5itfOo3GT",
        "outputId": "287d8538-dbf8-462e-fedb-73778421e058"
      },
      "id": "k8m5itfOo3GT",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a592b414",
      "metadata": {
        "id": "a592b414"
      },
      "source": [
        "3\\. Примените преобразование `AddToken` из пакета `torchtext`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.transforms import AddToken"
      ],
      "metadata": {
        "id": "FErPqaDMpJVN"
      },
      "id": "FErPqaDMpJVN",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxYDfKHPpwYr",
        "outputId": "64b6be80-899a-46ae-9f3e-d4ee2564b1f0"
      },
      "id": "MxYDfKHPpwYr",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[13, 4, 11, 0, 3, 14, 6, 9, 10], [13, 7, 12, 5, 8, 1, 2, -1, -1]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add = AddToken(token=999, begin=True)\n",
        "add(corpus_i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrXzMQEdpoDM",
        "outputId": "b0c486b7-b36c-4231-882d-7cbe5748cdbe"
      },
      "id": "OrXzMQEdpoDM",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[999, 13, 4, 11, 0, 3, 14, 6, 9, 10], [999, 13, 7, 12, 5, 8, 1, 2, -1, -1]]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d7b6d63",
      "metadata": {
        "id": "4d7b6d63"
      },
      "source": [
        "## Задачи для самостоятельного решения"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fadc01f5",
      "metadata": {
        "id": "fadc01f5"
      },
      "source": [
        "<p class=\"task\" id=\"1\"></p>\n",
        "\n",
        "1\\. Опишите класс `Vocab`. При создании объекта `Vocab` в конструктор передается набор текстов, предварительно разбитых на токены. Объект должен позволять:\n",
        "* по токену получить его уникальный индекс (в случае отсутствия токена в словаре вернуть 1)\n",
        "* по индексу токена получить сам токен (в случае отсутствия токена в словаре вернуть `<UNK>`)\n",
        "\n",
        "Первые 4 индекса зарезервированы под специальные токены `<PAD>`, `<UNK>`, `<SOS>`, `<EOS>`.\n",
        "    \n",
        "Создайте `Vocab` на основе списка `corpus` и закодируйте каждый токен в предложениях, используя `Vocab`. Выведите полученный результат на экран.\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02705b97-6ce7-42ac-9f4a-9c4f75cb6a05",
        "id": "n_2q3RfxwK6q"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "id": "n_2q3RfxwK6q"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f3a41634",
      "metadata": {
        "id": "f3a41634"
      },
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "        self.tokens = ['<PAD>', '<UNK>', '<SOS>', '<EOS>']\n",
        "        words = set()\n",
        "        for text in data:\n",
        "          words.update(text)\n",
        "        self.tokens.extend(list(words))\n",
        "        self.n_tokens = len(self.tokens)\n",
        "        self.uniwords = words\n",
        "\n",
        "        self.vocab = {token: idx for idx, token in enumerate(self.tokens)}\n",
        "\n",
        "    def itos(self, idx):\n",
        "        \"\"\"Возвращает токен по индексу\"\"\"\n",
        "        if idx < self.n_tokens:\n",
        "          return self.tokens[idx]\n",
        "        return '<UNK>'\n",
        "\n",
        "    def stoi(self, s):\n",
        "        \"\"\"Возвращает индекс токена\"\"\"\n",
        "        return self.vocab.get(s, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aa8656b5",
      "metadata": {
        "id": "aa8656b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4ac4c4-b926-47b4-f1ae-40b1ec431113"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 24, 33, 18, 16, 17],\n",
              " [27, 6, 23, 4, 34, 15, 12],\n",
              " [24, 10, 22, 11, 25, 28],\n",
              " [6, 7, 9, 26, 30, 4, 19, 13, 14],\n",
              " [21, 6, 32, 31, 29, 20, 8]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "corpus = [\n",
        "    \"Маленький котенок игриво прыгает за шариком\",\n",
        "    \"Пушистый котик мурлыкает, лежа на солнышке\",\n",
        "    \"Котенок любопытно нюхает цветы в саду\",\n",
        "    \"Котик ловко лазает по дереву, исследуя окружающий мир\",\n",
        "    \"Спящий котик мило моргает своими яркими глазками\",\n",
        "]\n",
        "\n",
        "corpus_t = [\n",
        "    word_tokenize(text.lower())\n",
        "    for text in corpus\n",
        "]\n",
        "\n",
        "vcb = Vocab(corpus_t)\n",
        "\n",
        "corpus_i = [\n",
        "    [vcb.stoi(t) for t in tokens]\n",
        "    for tokens in corpus_t\n",
        "]\n",
        "corpus_i"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb3a54b",
      "metadata": {
        "id": "0cb3a54b"
      },
      "source": [
        "<p class=\"task\" id=\"2\"></p>\n",
        "\n",
        "2\\. Создайте класс `NewsDataset` на основе данных из файла `news.csv`. Реализуйте метод `__getitem__` таким образом, чтобы он возвращал набор индексов токенов для заголовка новости (или новостей, если используются срезы) и метки классов для этих новостей. Для кодирования текстов используйте собственную реализацию `Vocab`. Там, где это возможно, возвращайте результат в виде тензора, а не списка.\n",
        "\n",
        "Выведите на экран результат выполнения `dataset[0]` и `dataset[:3]`\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch as th\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "2R8Tblhw22eG"
      },
      "id": "2R8Tblhw22eG",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.texts = data['text'].apply(lambda x: word_tokenize(x.lower()))\n",
        "    self.labels = th.tensor(data['label'].values)\n",
        "    self.vocab = Vocab(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    list_of_tokens = self.texts.iloc[idx]\n",
        "    if isinstance(idx, int):\n",
        "      list_of_tokens = [list_of_tokens]\n",
        "    corpus_i = [th.tensor([self.vocab.stoi(t) for t in tokens]) for tokens in list_of_tokens]\n",
        "    return corpus_i, self.labels[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]"
      ],
      "metadata": {
        "id": "ltCQE_dOxjYX"
      },
      "id": "ltCQE_dOxjYX",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('news.csv')\n",
        "ds = NewsDataset(df)\n",
        "\n",
        "ds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VootfF49RX0",
        "outputId": "df42b913-7bfe-4ffc-b64b-534b3a957d27"
      },
      "id": "0VootfF49RX0",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor([2413, 2045, 5542, 5377,  524, 4711])], tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULbzmXct92AA",
        "outputId": "17a17b8f-1ea4-4438-d874-d4151ffa4557"
      },
      "id": "ULbzmXct92AA",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor([2413, 2045, 5542, 5377,  524, 4711]),\n",
              "  tensor([4460, 1739, 2085, 1089, 2852,    8, 5540, 3378, 5596]),\n",
              "  tensor([2413,  645, 2020, 1306,  417,    8, 5540, 4551, 5034, 1503])],\n",
              " tensor([0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKuRLHdQXv-b",
        "outputId": "be44c74d-9455-4755-bd16-3c83687c6c5f"
      },
      "id": "kKuRLHdQXv-b",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1101"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda17cdd",
      "metadata": {
        "id": "fda17cdd"
      },
      "source": [
        "<p class=\"task\" id=\"3\"></p>\n",
        "\n",
        "3\\. Реализуйте преобразование `Truncate`, которое обрезает каждый текст в батче до `n` токенов. Создайте версию `NewsDataset` с обрезкой предложений до 5 токенов. Выведите на экран результат выполнения `dataset[0]` и `dataset[:3]`\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "21b3ab8a",
      "metadata": {
        "id": "21b3ab8a"
      },
      "outputs": [],
      "source": [
        "class Truncate:\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self, corpus_i):\n",
        "      return corpus_i[:self.n]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDatasetTruncate(Dataset):\n",
        "  def __init__(self, data, truncate):\n",
        "    self.texts = data['text'].apply(lambda x: word_tokenize(x.lower()))\n",
        "    self.labels = th.tensor(data['label'].values)\n",
        "    self.vocab = Vocab(self.texts)\n",
        "    self.truncate = truncate\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    list_of_tokens = self.texts.iloc[idx]\n",
        "    if isinstance(idx, int):\n",
        "      list_of_tokens = [list_of_tokens]\n",
        "    corpus_i = th.tensor([[self.vocab.stoi(t) for t in self.truncate(tokens)] for tokens in list_of_tokens])\n",
        "    return corpus_i, self.labels[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]"
      ],
      "metadata": {
        "id": "8mipMXsLJrMv"
      },
      "id": "8mipMXsLJrMv",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('news.csv')\n",
        "tr = Truncate(5)\n",
        "ds_tr = NewsDatasetTruncate(df, tr)\n",
        "\n",
        "ds_tr[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiifF7gJJxYG",
        "outputId": "89831ad7-bcb7-4e6a-c20e-882583b7ff5a"
      },
      "id": "EiifF7gJJxYG",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2413, 2045, 5542, 5377,  524]]), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_tr[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eddGFIp7JxSf",
        "outputId": "709a3874-888b-4103-9f5f-754aa2eb5631"
      },
      "id": "eddGFIp7JxSf",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2413, 2045, 5542, 5377,  524],\n",
              "         [4460, 1739, 2085, 1089, 2852],\n",
              "         [2413,  645, 2020, 1306,  417]]),\n",
              " tensor([0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bfcac69",
      "metadata": {
        "id": "5bfcac69"
      },
      "source": [
        "<p class=\"task\" id=\"4\"></p>\n",
        "\n",
        "4\\. Реализуйте преобразование `Pad`, которое расширяет каждый текст в батче до `n` токенов значением `pad_idx`. Создайте версию `NewsDataset` с расширением предложений до 30 токенов. Выведите на экран результат выполнения `dataset[0]` и `dataset[:3]`\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "842d669c",
      "metadata": {
        "id": "842d669c"
      },
      "outputs": [],
      "source": [
        "class Pad:\n",
        "    def __init__(self, n, pad_idx):\n",
        "        self.n = n\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, text):\n",
        "      padd = [self.pad_idx]*(self.n-len(text))\n",
        "      text.extend(padd)\n",
        "      return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDatasetPad(Dataset):\n",
        "  def __init__(self, data, pad=None):\n",
        "    self.texts = data['text'].apply(lambda x: word_tokenize(x.lower()))\n",
        "    self.labels = th.tensor(data['label'].values)\n",
        "    self.vocab = Vocab(self.texts)\n",
        "\n",
        "    if pad:\n",
        "      self.pad = pad\n",
        "    else:\n",
        "      self.pad = lambda x: x\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    list_of_tokens = self.texts.iloc[idx]\n",
        "    if isinstance(idx, int):\n",
        "      list_of_tokens = [list_of_tokens]\n",
        "\n",
        "    corpus_i = th.tensor([self.pad([self.vocab.stoi(t) for t in tokens]) for tokens in list_of_tokens])\n",
        "\n",
        "    return corpus_i, self.labels[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]"
      ],
      "metadata": {
        "id": "yn4y4h-GM_Lw"
      },
      "id": "yn4y4h-GM_Lw",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('news.csv')\n",
        "pad = Pad(30,0)\n",
        "ds_pad = NewsDatasetPad(df, pad)\n",
        "\n",
        "ds_pad[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-uh4LNrO9ci",
        "outputId": "ececac1d-8e89-45db-ff5f-8a7e7a69dc11"
      },
      "id": "8-uh4LNrO9ci",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2413, 2045, 5542, 5377,  524, 4711,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0]]),\n",
              " tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_pad[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXdcd03bQCuE",
        "outputId": "893bf0ff-c999-4e6c-d99d-3408d76eea7f"
      },
      "id": "qXdcd03bQCuE",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_pad[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8HYxRHiPT3N",
        "outputId": "0412147b-bbf4-4c5e-d1bb-fd4c8e51c47a"
      },
      "id": "L8HYxRHiPT3N",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2413, 2045, 5542, 5377,  524, 4711,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0],\n",
              "         [4460, 1739, 2085, 1089, 2852,    8, 5540, 3378, 5596,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0],\n",
              "         [2413,  645, 2020, 1306,  417,    8, 5540, 4551, 5034, 1503,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0]]),\n",
              " tensor([0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_pad[:3][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfRfyddRQAZl",
        "outputId": "7037ebb5-be46-4b2b-8bce-43911f3eadf5"
      },
      "id": "SfRfyddRQAZl",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b8d1f46",
      "metadata": {
        "id": "4b8d1f46"
      },
      "source": [
        "<p class=\"task\" id=\"5\"></p>\n",
        "\n",
        "5\\. Создайте объект `torchtext.vocab.Vocab` на основе данных из файла `news.csv`. Первые 4 индекса зарезервируйте под специальные токены `<PAD>`, `<UNK>`, `<SOS>`, `<EOS>`. Опишите класс `NewsDatasetTorchText`, аналогичный по функционалу классу `NewsDataset`, но использующего реализацию `torchtext.vocab.Vocab`. Выведите на экран результат выполнения `dataset[0]` и `dataset[:3]`\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.transforms import AddToken"
      ],
      "metadata": {
        "id": "5IklWXMOQsh_"
      },
      "execution_count": 18,
      "outputs": [],
      "id": "5IklWXMOQsh_"
    },
    {
      "cell_type": "code",
      "source": [
        "build_vocab_from_iterator(corpus_t, specials=['<PAD>', '<UNK>', '<SOS>', '<EOS>'], special_first=True).lookup_tokens([0,1,2,3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yUMXef-Rzi1",
        "outputId": "07ea950e-5c51-454e-8f65-c04c768d3387"
      },
      "id": "9yUMXef-Rzi1",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PAD>', '<UNK>', '<SOS>', '<EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDatasetTorchText:\n",
        "  def __init__(self, data):\n",
        "    self.texts = data['text'].apply(lambda x: word_tokenize(x.lower()))\n",
        "    self.labels = th.tensor(data['label'].values)\n",
        "    self.vocab = build_vocab_from_iterator(self.texts, specials=['<PAD>', '<UNK>', '<SOS>', '<EOS>'], special_first=True)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    list_of_tokens = self.texts.iloc[idx]\n",
        "    if isinstance(idx, int):\n",
        "      list_of_tokens = [list_of_tokens]\n",
        "    corpus_i = [th.tensor(self.vocab(tokens)) for tokens in list_of_tokens]\n",
        "    return corpus_i, self.labels[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]"
      ],
      "metadata": {
        "id": "nneVTJEoP3qw"
      },
      "id": "nneVTJEoP3qw",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('news.csv')\n",
        "ds_torchtext = NewsDatasetTorchText(df)\n",
        "\n",
        "ds_torchtext[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66dfcbe-7d6f-4de0-d3df-303bc4120fa1",
        "id": "pBxaUtJwT6s3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor([  31,  203, 3355, 5413,  491, 3095])], tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor([  31,  203, 3355, 5413,  491, 3095])], tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "id": "pBxaUtJwT6s3"
    },
    {
      "cell_type": "code",
      "source": [
        "ds_torchtext[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4444d45c-e048-4cad-c522-941edd22e913",
        "id": "bgiuX4XvT6tA"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor([  31,  203, 3355, 5413,  491, 3095]),\n",
              "  tensor([  27,  147, 3913,    4,  379,   12,   10, 2422, 4484]),\n",
              "  tensor([  31,   63,   29, 4036,  318,   12,   10, 3667,  568,  991])],\n",
              " tensor([0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "id": "bgiuX4XvT6tA"
    },
    {
      "cell_type": "markdown",
      "id": "818632b2",
      "metadata": {
        "id": "818632b2"
      },
      "source": [
        "<p class=\"task\" id=\"6\"></p>\n",
        "\n",
        "6\\. Создайте преобразование, которое последовательно:\n",
        "* преобразует набор токенов в последовательность индексов;\n",
        "* преобразует результат в тензор;\n",
        "* расширяет предложения до 30 символов, заполняя недостающие позиции индексом 0.\n",
        "\n",
        "Создайте версию NewsDatasetTorchText с указанием этого преобразования. Выведите на экран результат выполнения `dataset[0]` и `dataset[:3]`\n",
        "\n",
        "- [ ] Проверено на семинаре"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th.cat((th.tensor([1,2,3]),th.full((5-3,), 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ru0iNAqYcgO",
        "outputId": "ba2ef84b-1595-499a-e575-42b68a3a377d"
      },
      "id": "5Ru0iNAqYcgO",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transform:\n",
        "  def __init__(self, vcb, n, pad_idx):\n",
        "    self.vcb = vcb\n",
        "    self.n = n\n",
        "    self.pad_idx = pad_idx\n",
        "\n",
        "  def __call__(self, tokens):\n",
        "    out = self.vcb.lookup_indices(tokens)\n",
        "    out = th.tensor(out)\n",
        "    out = th.cat((out,th.full((self.n-out.shape[0],), self.pad_idx)))\n",
        "    return out"
      ],
      "metadata": {
        "id": "sVhyNGHOP4SL"
      },
      "id": "sVhyNGHOP4SL",
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDatasetTorchText2:\n",
        "  def __init__(self, data, transform, n=30, pad_idx=0):\n",
        "    self.texts = data['text'].apply(lambda x: word_tokenize(x.lower()))\n",
        "    self.labels = th.tensor(data['label'].values)\n",
        "    self.vocab = build_vocab_from_iterator(self.texts, specials=['<PAD>', '<UNK>', '<SOS>', '<EOS>'], special_first=True)\n",
        "    self.transform = transform(self.vocab, n, pad_idx)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    list_of_tokens = self.texts.iloc[idx]\n",
        "    if isinstance(idx, int):\n",
        "      list_of_tokens = [list_of_tokens]\n",
        "    corpus_i = th.stack([self.transform(tokens) for tokens in list_of_tokens], dim=0)\n",
        "    return corpus_i, self.labels[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.labels.shape[0]"
      ],
      "metadata": {
        "id": "bB1GJex_WxmS"
      },
      "id": "bB1GJex_WxmS",
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('news.csv')\n",
        "ds_torchtext2 = NewsDatasetTorchText2(df, Transform)\n",
        "\n",
        "ds_torchtext2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAmRa4EVZ28u",
        "outputId": "193c85e9-7fe9-4a02-cb27-b3c8fc6d9a59"
      },
      "id": "qAmRa4EVZ28u",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  31,  203, 3355, 5413,  491, 3095,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0]]),\n",
              " tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_torchtext2[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPaDQ3xlagxp",
        "outputId": "98a45626-bf4e-46cd-d885-1930811c566f"
      },
      "id": "MPaDQ3xlagxp",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  31,  203, 3355, 5413,  491, 3095,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0],\n",
              "         [  27,  147, 3913,    4,  379,   12,   10, 2422, 4484,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0],\n",
              "         [  31,   63,   29, 4036,  318,   12,   10, 3667,  568,  991,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0]]),\n",
              " tensor([0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66caa919",
      "metadata": {
        "id": "66caa919"
      },
      "source": [
        "## Обратная связь\n",
        "- [ ] Хочу получить обратную связь по решению"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}